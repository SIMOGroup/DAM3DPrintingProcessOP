{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T01:26:25.243655Z",
     "iopub.status.busy": "2022-01-04T01:26:25.243290Z",
     "iopub.status.idle": "2022-01-04T01:27:02.325877Z",
     "shell.execute_reply": "2022-01-04T01:27:02.324873Z",
     "shell.execute_reply.started": "2022-01-04T01:26:25.243567Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install trimesh openpyxl open3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T01:27:02.329590Z",
     "iopub.status.busy": "2022-01-04T01:27:02.328948Z",
     "iopub.status.idle": "2022-01-04T01:27:03.642269Z",
     "shell.execute_reply": "2022-01-04T01:27:03.641367Z",
     "shell.execute_reply.started": "2022-01-04T01:27:02.329543Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import trimesh\n",
    "import glob\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_path = \"/kaggle/input/3dattributes\" # thư mục chứa file get-data.xlsx\n",
    "obj_path = \"kaggle/input/3dobject/3d model\" # thư mục chứ file .obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T03:49:14.796496Z",
     "iopub.status.busy": "2022-01-04T03:49:14.796192Z",
     "iopub.status.idle": "2022-01-04T03:49:15.999317Z",
     "shell.execute_reply": "2022-01-04T03:49:15.998437Z",
     "shell.execute_reply.started": "2022-01-04T03:49:14.796466Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel(f\"{att_path}/get-data.xlsx\", sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T03:49:38.065446Z",
     "iopub.status.busy": "2022-01-04T03:49:38.064578Z",
     "iopub.status.idle": "2022-01-04T03:53:12.267212Z",
     "shell.execute_reply": "2022-01-04T03:53:12.265559Z",
     "shell.execute_reply.started": "2022-01-04T03:49:38.065397Z"
    }
   },
   "outputs": [],
   "source": [
    "samples = {} # biến chứa dữ liệu của tất cả các object, mỗi object chứa 3 thông tin\n",
    "for sheet in tqdm(data.keys(), position=0):\n",
    "    obj_id = sheet.split(\"Sheet\")[-1].strip() # lấy object id từ tên sheet\n",
    "    try:\n",
    "        obj = trimesh.load_mesh(f\"{obj_path}/{obj_id}.obj\", process=False)\n",
    "    except:\n",
    "        obj = trimesh.load_mesh(f\"{obj_path}/{obj_id}.OBJ\", process=False) # có một obj có đuôi là OBJ mà em lỡ up lên kaggle rồi nên phải try except :v, thầy đổi cái đuôi của file .OBJ thành .obj thì khỏi bỏ cái try except này cũng đc\n",
    "    atts = data[sheet].dropna(how=\"all\").dropna(axis=1, how=\"all\").iloc[2:] # tất hàng và cột chứa tất cả giá trị là Nan, lấy từ hàm thứ 2 đổ đi vì 2 hàng đầu là \"Input\" và tên cột\n",
    "    atts.drop(atts.columns[0], axis=1, inplace=True) # bỏ cột STT\n",
    "    atts.columns = [\"extrution_width\", \"layer_height\", \"speed\", \"infill\", \"time\", \"length\", \"weight\"] # đặt lại tên cột\n",
    "    atts.reset_index(drop=True, inplace=True) # đặt lại index\n",
    "    atts[\"volume\"] = obj.volume # thêm cột volume\n",
    "    atts[\"area\"] = obj.area # thêm cột area\n",
    "    samples[obj_id] = { # mỗi object có 3 thông tin: vertices, attributes(4 cột đâu của file xlsx và 2 cột thông số của object), nhãn (3 cột cuối của file xlsx)\n",
    "        \"obj\": obj,\n",
    "        \"atts\": atts[[\"extrution_width\", \"layer_height\", \"speed\", \"infill\", \"volume\", \"area\"]],\n",
    "        \"targets\": atts[[\"time\",\"length\",\"weight\"]]\n",
    "    }\n",
    "samples[list(samples.keys())[0]][\"obj\"].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T03:44:37.983215Z",
     "iopub.status.busy": "2022-01-04T03:44:37.982905Z",
     "iopub.status.idle": "2022-01-04T03:44:38.000576Z",
     "shell.execute_reply": "2022-01-04T03:44:37.999689Z",
     "shell.execute_reply.started": "2022-01-04T03:44:37.983185Z"
    }
   },
   "outputs": [],
   "source": [
    "samples[list(samples.keys())[64]][\"atts\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[list(samples.keys())[64]][\"targets\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reduce vertices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T03:54:07.588485Z",
     "iopub.status.busy": "2022-01-04T03:54:07.588080Z",
     "iopub.status.idle": "2022-01-04T04:09:15.323251Z",
     "shell.execute_reply": "2022-01-04T04:09:15.321734Z",
     "shell.execute_reply.started": "2022-01-04T03:54:07.588437Z"
    }
   },
   "outputs": [],
   "source": [
    "# tìm số faces nhỏ nhất trong tất cả object\n",
    "min_faces = len(samples[\"1\"][\"obj\"].faces)\n",
    "for obj_id in samples.keys():\n",
    "    n_faces = len(samples[obj_id][\"obj\"].faces)\n",
    "    if n_faces < min_faces:\n",
    "        min_faces = n_faces\n",
    "print(\"Min n_faces: \", min_faces)\n",
    "\n",
    "# giảm face của tất cả object về bằng số face nhỏ nhất và tìm số vertices nhỏ nhất, \n",
    "# vì sau khi giảm face của object thì độ chênh lệch vertice giữa các object chỉ vài cái nên tìm số v nhỏ nhất để những cái nào nhiều v hơn thì sẽ bỏ cho bằng v nhỏ nhất\n",
    "min_vertices = len(samples[\"1\"][\"obj\"].vertices)\n",
    "for obj_id in samples.keys():\n",
    "    samples[obj_id][\"obj\"] = samples[obj_id][\"obj\"].simplify_quadratic_decimation(min_faces) # hàm giảm face\n",
    "    n_vertices = len(samples[obj_id][\"obj\"].vertices)\n",
    "    if n_vertices < min_vertices:\n",
    "        min_vertices = n_vertices\n",
    "print(\"Min n_vertices\", min_vertices)\n",
    "\n",
    "# giảm v của mọi obj về bằng v nhỏ nhất\n",
    "for obj_id in samples.keys():\n",
    "    mask = np.full(len(samples[obj_id][\"obj\"].vertices), True) # tạo mask\n",
    "    remove = len(samples[obj_id][\"obj\"].vertices) - min_vertices # số lượng v của obj hiện tại cần bỏ để bằng với số v nhỏ nhất\n",
    "    if remove > 0: \n",
    "        mask[-remove:] = False # bỏ lượng chênh lệch ở cuối\n",
    "        samples[obj_id][\"obj\"].update_vertices(mask) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T04:10:01.308272Z",
     "iopub.status.busy": "2022-01-04T04:10:01.307968Z",
     "iopub.status.idle": "2022-01-04T04:10:01.315920Z",
     "shell.execute_reply": "2022-01-04T04:10:01.314616Z",
     "shell.execute_reply.started": "2022-01-04T04:10:01.308242Z"
    }
   },
   "outputs": [],
   "source": [
    "# lưu 3 thông tin của tất cả obj thành 3 list để tiền xử lý\n",
    "vertices = []\n",
    "attributes = []\n",
    "targets = []\n",
    "for obj_id in samples.keys():\n",
    "    vertices.append(samples[obj_id][\"obj\"].vertices) # chỉ lấy vertices\n",
    "    attributes.append(samples[obj_id][\"atts\"])\n",
    "    targets.append(samples[obj_id][\"targets\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T04:10:02.366257Z",
     "iopub.status.busy": "2022-01-04T04:10:02.365711Z",
     "iopub.status.idle": "2022-01-04T04:10:02.372971Z",
     "shell.execute_reply": "2022-01-04T04:10:02.372044Z",
     "shell.execute_reply.started": "2022-01-04T04:10:02.366214Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "v_train, v_test, a_train, a_test, y_train, y_test = train_test_split(vertices, attributes, targets, test_size=0.2) # chia train test cho 3 thông tin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T04:10:03.684925Z",
     "iopub.status.busy": "2022-01-04T04:10:03.684427Z",
     "iopub.status.idle": "2022-01-04T04:10:13.040907Z",
     "shell.execute_reply": "2022-01-04T04:10:13.039631Z",
     "shell.execute_reply.started": "2022-01-04T04:10:03.684887Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# vì mỗi obj có nhiều vertices(v) và nhiều attributes(a), mỗi v và mỗi a lại có nhiều cột, \n",
    "# nên để scale tất cả dữ liệu theo từng cột thì ta phải nối từng cột của tất cả obj lại với nhau sau đó thực hiện scale\n",
    "\n",
    "print(np.array(v_train).shape)\n",
    "print(np.array(a_train).shape)\n",
    "print(np.array(y_train).shape)\n",
    "\n",
    "# mỗi phần tử có nhiều v nên nếu nối cột lại với nhau thì v sẽ liên tiếp nhau, nên giữ lại số lượng v của 1 obj để sau khi scale xong ta sẽ chia lại v cho mỗi obj\n",
    "len_v = len(v_train[0])\n",
    "len_a = len(a_train[0]) # tương tự với a, mỗi obj chỉ có 1 y nên ko cần nhớ số lượng y\n",
    "\n",
    "v_train_sc = []\n",
    "a_train_sc = pd.DataFrame()\n",
    "y_train_sc = pd.DataFrame() # nối y luôn để scale\n",
    "\n",
    "# nối tập train\n",
    "for i in range(len(v_train)):\n",
    "    v_train_sc.extend(v_train[i])\n",
    "    a_train_sc = pd.concat([a_train_sc, a_train[i]])\n",
    "    y_train_sc = pd.concat([y_train_sc, y_train[i]])\n",
    "\n",
    "# nối tập test\n",
    "v_test_sc = []\n",
    "a_test_sc = pd.DataFrame()\n",
    "y_test_sc = pd.DataFrame()\n",
    "for i in range(len(v_test)):\n",
    "    v_test_sc.extend(v_test[i])\n",
    "    a_test_sc = pd.concat([a_test_sc, a_test[i]])\n",
    "    y_test_sc = pd.concat([y_test_sc, y_test[i]])\n",
    "\n",
    "# fit và scale tập train sau đó dùng scale đó scale cho tập test\n",
    "v_scaler = MinMaxScaler()\n",
    "v_train_sc = v_scaler.fit_transform(v_train_sc)\n",
    "v_test_sc = v_scaler.transform(v_test_sc)\n",
    "\n",
    "# tương tự cho a\n",
    "a_scaler = MinMaxScaler()\n",
    "a_train_sc = a_scaler.fit_transform(a_train_sc)\n",
    "a_test_sc = a_scaler.transform(a_test_sc)\n",
    "\n",
    "# tương tự cho y\n",
    "y_scaler = MinMaxScaler()\n",
    "y_train_sc = y_scaler.fit_transform(y_train_sc)\n",
    "y_test_sc = y_scaler.transform(y_test_sc)\n",
    "\n",
    "for i in range(len(v_train.copy())):\n",
    "    v_train[i] = v_train_sc[i*len_v:(i+1)*len_v]\n",
    "    a_train[i] = a_train_sc[i*len_a:(i+1)*len_a]\n",
    "    y_train[i] = y_train_sc[i:i+1]\n",
    "\n",
    "# chia lại v,a,y cho mỗi obj\n",
    "for i in range(len(v_test.copy())):\n",
    "    v_test[i] = v_test_sc[i*len_v:(i+1)*len_v]\n",
    "    a_test[i] = a_test_sc[i*len_a:(i+1)*len_a]\n",
    "    y_test[i] = y_test_sc[i:i+1]\n",
    "\n",
    "y_train = np.array(y_train).squeeze() # y dư 1 dim nên giảm dim\n",
    "v_train = np.array(v_train)\n",
    "a_train = np.array(a_train)\n",
    "\n",
    "y_test = np.array(y_test).squeeze() # y dư 1 dim nên giảm dim\n",
    "v_test = np.array(v_test)\n",
    "a_test = np.array(a_test)\n",
    "\n",
    "# kiểm tra lại shape xem có bằng với ban đầu chưa\n",
    "print(v_train.shape)\n",
    "print(a_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T04:10:18.692596Z",
     "iopub.status.busy": "2022-01-04T04:10:18.692262Z",
     "iopub.status.idle": "2022-01-04T04:10:18.697837Z",
     "shell.execute_reply": "2022-01-04T04:10:18.696875Z",
     "shell.execute_reply.started": "2022-01-04T04:10:18.692562Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T04:10:20.649577Z",
     "iopub.status.busy": "2022-01-04T04:10:20.649259Z",
     "iopub.status.idle": "2022-01-04T04:10:20.769846Z",
     "shell.execute_reply": "2022-01-04T04:10:20.769065Z",
     "shell.execute_reply.started": "2022-01-04T04:10:20.649548Z"
    }
   },
   "outputs": [],
   "source": [
    "obj_inputs = Input(shape=v_train[0].shape)\n",
    "att_inputs = Input(shape=a_train[0].shape)\n",
    "\n",
    "# CNN cho v\n",
    "nodes = Conv1D(32, kernel_size=3)(obj_inputs)\n",
    "nodes = MaxPooling1D()(nodes)\n",
    "nodes = SpatialDropout1D(0.1)(nodes)\n",
    "nodes = Flatten()(nodes)\n",
    "obj_outputs = Dense(5)(nodes) # output shape (,5)\n",
    "\n",
    "# CNN cho a, không nối được output của v với a vì shape của output v là (, 5) còn shape của a là (,6,32) (6 cột 32 hàng) nên tạm thời em bỏ a vào 1 cái cnn y chang cnn của v luôn\n",
    "nodes = Conv1D(32, kernel_size=3)(att_inputs)\n",
    "nodes = MaxPooling1D()(nodes)\n",
    "nodes = SpatialDropout1D(0.1)(nodes)\n",
    "nodes = Flatten()(nodes)\n",
    "att_outputs = Dense(5)(nodes) # output shape (,5)\n",
    "\n",
    "# gộp 2 output lại thành 1 input\n",
    "total_inputs = Concatenate()([obj_outputs, att_outputs])\n",
    "\n",
    "nodes = Dense(64)(total_inputs)\n",
    "nodes = Dropout(0.1)(nodes)\n",
    "outputs = Dense(3)(nodes)\n",
    "\n",
    "model = Model(inputs=[obj_inputs, att_inputs], outputs=outputs)\n",
    "model.compile(loss=\"mae\", optimizer=Adam())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T04:12:51.046768Z",
     "iopub.status.busy": "2022-01-04T04:12:51.046436Z",
     "iopub.status.idle": "2022-01-04T04:12:57.879225Z",
     "shell.execute_reply": "2022-01-04T04:12:57.878340Z",
     "shell.execute_reply.started": "2022-01-04T04:12:51.046733Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(x=[v_train, a_train], y=y_train, epochs=10, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T04:11:57.708147Z",
     "iopub.status.busy": "2022-01-04T04:11:57.707845Z",
     "iopub.status.idle": "2022-01-04T04:11:57.969017Z",
     "shell.execute_reply": "2022-01-04T04:11:57.968091Z",
     "shell.execute_reply.started": "2022-01-04T04:11:57.708113Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(model.history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T04:38:56.593245Z",
     "iopub.status.busy": "2022-01-04T04:38:56.592974Z",
     "iopub.status.idle": "2022-01-04T04:38:56.831906Z",
     "shell.execute_reply": "2022-01-04T04:38:56.831024Z",
     "shell.execute_reply.started": "2022-01-04T04:38:56.593216Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = model.predict([v_test, a_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T04:48:56.190091Z",
     "iopub.status.busy": "2022-01-04T04:48:56.189783Z",
     "iopub.status.idle": "2022-01-04T04:48:56.196933Z",
     "shell.execute_reply": "2022-01-04T04:48:56.195938Z",
     "shell.execute_reply.started": "2022-01-04T04:48:56.190051Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T04:48:42.695452Z",
     "iopub.status.busy": "2022-01-04T04:48:42.695128Z",
     "iopub.status.idle": "2022-01-04T04:48:42.702249Z",
     "shell.execute_reply": "2022-01-04T04:48:42.701469Z",
     "shell.execute_reply.started": "2022-01-04T04:48:42.695421Z"
    }
   },
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T04:48:18.814191Z",
     "iopub.status.busy": "2022-01-04T04:48:18.813857Z",
     "iopub.status.idle": "2022-01-04T04:48:18.821198Z",
     "shell.execute_reply": "2022-01-04T04:48:18.820259Z",
     "shell.execute_reply.started": "2022-01-04T04:48:18.814155Z"
    }
   },
   "outputs": [],
   "source": [
    "np.mean(np.abs(preds - y_test) / y_test * 100) # độ khác nhau trung bình (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
